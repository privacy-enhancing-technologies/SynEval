SynEval’s so-called “membership inference attack” just trains a classifier to tell synthetic rows from original rows. That tests distributional distinguishability, not the classical model-based MIA threat model. As a result, heavily perturbed (and thus safe) synthetic data can look like “high risk.” We should relabel the metric or replace it with a true model-centric MIA workflow that uses a downstream model and assesses whether training membership can actually be inferred. Until that rework lands, treat the current score as a similarity diagnostic, not a privacy guarantee.
