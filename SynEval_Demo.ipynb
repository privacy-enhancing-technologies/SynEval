{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUMKytyYITGn"
      },
      "source": [
        "# SynEval: Synthetic Data Evaluation Framework\n",
        "\n",
        "SynEval is a comprehensive evaluation framework for assessing the quality of synthetic data generated by Large Language Models (LLMs). The framework provides quantitative scoring across four key dimensions:\n",
        "\n",
        "- **Fidelity**: Measures how well the synthetic data preserves the statistical properties and patterns of the original data\n",
        "- **Utility**: Evaluates the usefulness of synthetic data for downstream tasks\n",
        "- **Diversity**: Assesses the variety and uniqueness of the generated data\n",
        "- **Privacy**: Analyzes the privacy protection level of the synthetic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwIKg4kF1whz"
      },
      "source": [
        "Find SynEval directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlLm-nOv1mTq"
      },
      "outputs": [],
      "source": [
        "cd SynEval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csr7yWHDQ_J5",
        "outputId": "f20c39fe-d017-458b-9ed6-980ca6dfcd74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "amazon_fashion_ner_analysis_fast.py  privacy_result.json\n",
            "\u001b[0m\u001b[01;34mcache\u001b[0m/                               privacy_results.json\n",
            "claude.csv                           \u001b[01;34mprivacy_visualizations\u001b[0m/\n",
            "diversity.py                         \u001b[01;34m__pycache__\u001b[0m/\n",
            "diversity_results.json               pyproject.toml\n",
            "download_nltk_data.py                README_amazon_fashion_analysis.md\n",
            "fidelity.py                          README.md\n",
            "fidelity_results.json                real_10k.csv\n",
            "flair_ner.py                         \u001b[01;34mreports\u001b[0m/\n",
            "LICENSE                              requirements_flair_ner.txt\n",
            "MANIFEST.in                          requirements.txt\n",
            "metadata.json                        run.py\n",
            "\u001b[01;34mplots\u001b[0m/                               setup.py\n",
            "plotting.py                          \u001b[01;34msyneval\u001b[0m/\n",
            "prepare_environment.py               utility.py\n",
            "privacy.py                           utility_results.json\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyuF6Kx51t3l"
      },
      "source": [
        "Install required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LibAfIpuRBeW",
        "outputId": "2c4d7c9c-ec01-450b-d7ec-b0e9f07357cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 SynEval Environment Preparation\n",
            "========================================\n",
            "📦 Installing Python dependencies...\n",
            "  Upgrading pip...\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "  Upgrading critical packages (numpy, scipy, gensim)...\n",
            "Collecting numpy>=1.26.0\n",
            "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.1 which is incompatible.\n",
            "anonymeter 1.0.0 requires numpy<1.27,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.39.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.1 which is incompatible.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.1\n",
            "    ✅ numpy>=1.26.0 upgraded successfully\n",
            "Collecting scipy<1.16.0,>=1.11.0\n",
            "  Using cached scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting numpy<2.5,>=1.23.5 (from scipy<1.16.0,>=1.11.0)\n",
            "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Using cached scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Installing collected packages: numpy, scipy\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.3.1\n",
            "\u001b[2K    Uninstalling numpy-2.3.1:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.3.1\n",
            "\u001b[2K  Attempting uninstall: scipy\n",
            "\u001b[2K    Found existing installation: scipy 1.13.1\n",
            "\u001b[2K    Uninstalling scipy-1.13.1:\n",
            "\u001b[2K      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [scipy]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.1 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\n",
            "anonymeter 1.0.0 requires numpy<1.27,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.39.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.1 which is incompatible.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.1 scipy-1.15.3\n",
            "    ✅ scipy>=1.11.0,<1.16.0 upgraded successfully\n",
            "Collecting gensim>=4.3.1\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim>=4.3.1)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim>=4.3.1)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim>=4.3.1)\n",
            "  Using cached smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim>=4.3.1)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "\u001b[2K  Attempting uninstall: wrapt\n",
            "\u001b[2K    Found existing installation: wrapt 1.17.2\n",
            "\u001b[2K    Uninstalling wrapt-1.17.2:\n",
            "\u001b[2K      Successfully uninstalled wrapt-1.17.2\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.3.1\n",
            "\u001b[2K    Uninstalling numpy-2.3.1:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.3.1\n",
            "\u001b[2K  Attempting uninstall: smart-open\n",
            "\u001b[2K    Found existing installation: smart_open 7.3.0.post1\n",
            "\u001b[2K    Uninstalling smart_open-7.3.0.post1:\n",
            "\u001b[2K      Successfully uninstalled smart_open-7.3.0.post1\n",
            "\u001b[2K  Attempting uninstall: scipy\n",
            "\u001b[2K    Found existing installation: scipy 1.15.3\n",
            "\u001b[2K    Uninstalling scipy-1.15.3:\n",
            "\u001b[2K      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[2K  Attempting uninstall: gensim\n",
            "\u001b[2K    Found existing installation: gensim 4.3.3\n",
            "\u001b[2K    Uninstalling gensim-4.3.3:\n",
            "\u001b[2K      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [gensim]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.39.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.3.0.post1 wrapt-1.17.2\n",
            "    ✅ gensim>=4.3.1 upgraded successfully\n",
            "  Installing remaining dependencies...\n",
            "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (from -r requirements.txt (line 22))\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m171.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Collecting numpy>=1.26.0 (from -r requirements.txt (line 3))\n",
            "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: scipy<1.16.0,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.13.1)\n",
            "Collecting scipy<1.16.0,>=1.11.0 (from -r requirements.txt (line 4))\n",
            "  Using cached scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: sdv>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.24.0)\n",
            "Requirement already satisfied: textblob>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.19.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.7.0)\n",
            "Requirement already satisfied: nltk>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (3.9.1)\n",
            "Requirement already satisfied: gensim>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.3.3)\n",
            "Requirement already satisfied: networkx>=3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.5)\n",
            "Requirement already satisfied: flair>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.15.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (3.10.3)\n",
            "Requirement already satisfied: spacy>=3.8.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (3.8.7)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: anonymeter>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.0.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.13.2)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2025.7.9)\n",
            "Requirement already satisfied: torch<2.2.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (2.1.2)\n",
            "Requirement already satisfied: torchvision<0.17.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.16.2)\n",
            "Requirement already satisfied: transformers<4.40.0,>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (4.39.3)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (2.3.7.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (12.6.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision<0.17.0,>=0.10.0->-r requirements.txt (line 19)) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision<0.17.0,>=0.10.0->-r requirements.txt (line 19)) (11.2.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (0.33.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.28 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (1.39.4)\n",
            "Requirement already satisfied: botocore<2.0.0,>=1.31 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (1.39.4)\n",
            "Requirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (0.21)\n",
            "Requirement already satisfied: copulas>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (0.12.3)\n",
            "Requirement already satisfied: ctgan>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: deepecho>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: rdt>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (1.17.1)\n",
            "Requirement already satisfied: sdmetrics>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (0.21.0)\n",
            "Requirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.11/dist-packages (from sdv>=0.18.0->-r requirements.txt (line 5)) (4.3.8)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2.0.0,>=1.28->sdv>=0.18.0->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2.0.0,>=1.28->sdv>=0.18.0->-r requirements.txt (line 5)) (0.13.0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv>=0.18.0->-r requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.8.1->-r requirements.txt (line 8)) (8.2.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.3.1->-r requirements.txt (line 9)) (7.3.0.post1)\n",
            "Requirement already satisfied: conllu<5.0.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (1.2.18)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (6.3.1)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (5.2.0)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (5.4.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (10.7.0)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (3.1)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (0.4.2)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from flair>=0.12.0->-r requirements.txt (line 11)) (2.1)\n",
            "Requirement already satisfied: jsonlines>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair>=0.12.0->-r requirements.txt (line 11)) (4.0.0)\n",
            "Requirement already satisfied: intervaltree in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair>=0.12.0->-r requirements.txt (line 11)) (3.1.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair>=0.12.0->-r requirements.txt (line 11)) (0.6.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair>=0.12.0->-r requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair>=0.12.0->-r requirements.txt (line 11)) (5.29.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (3.2.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (0.16.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (2.11.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.5->-r requirements.txt (line 13)) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.8.5->-r requirements.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.5->-r requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.5->-r requirements.txt (line 13)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.5->-r requirements.txt (line 13)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision<0.17.0,>=0.10.0->-r requirements.txt (line 19)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision<0.17.0,>=0.10.0->-r requirements.txt (line 19)) (3.10)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.8.5->-r requirements.txt (line 13)) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.8.5->-r requirements.txt (line 13)) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.5->-r requirements.txt (line 13)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.5->-r requirements.txt (line 13)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.5->-r requirements.txt (line 13)) (0.21.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim>=4.3.1->-r requirements.txt (line 9)) (1.17.2)\n",
            "Requirement already satisfied: numba~=0.58 in /usr/local/lib/python3.11/dist-packages (from anonymeter>=0.1.0->-r requirements.txt (line 15)) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba~=0.58->anonymeter>=0.1.0->-r requirements.txt (line 15)) (0.43.0)\n",
            "Requirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv>=0.18.0->-r requirements.txt (line 5)) (5.24.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair>=0.12.0->-r requirements.txt (line 11)) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair>=0.12.0->-r requirements.txt (line 11)) (4.13.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair>=0.12.0->-r requirements.txt (line 11)) (25.3.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.8.5->-r requirements.txt (line 13)) (1.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv>=0.18.0->-r requirements.txt (line 5)) (8.5.0)\n",
            "Requirement already satisfied: Faker>=17 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.17.0->sdv>=0.18.0->-r requirements.txt (line 5)) (37.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.8.5->-r requirements.txt (line 13)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.8.5->-r requirements.txt (line 13)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.8.5->-r requirements.txt (line 13)) (0.1.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (1.8.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->transformers<4.40.0,>=4.20.0->-r requirements.txt (line 20)) (5.9.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair>=0.12.0->-r requirements.txt (line 11)) (2.7)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair>=0.12.0->-r requirements.txt (line 11)) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (3.0.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair>=0.12.0->-r requirements.txt (line 11)) (1.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.2.0,>=1.9.0->-r requirements.txt (line 18)) (1.3.0)\n",
            "✅ Dependencies installed successfully!\n",
            "\n",
            "💡 Note: You may see dependency conflict warnings above.\n",
            "   This is normal in environments like Google Colab or when other packages are already installed.\n",
            "   These conflicts won't affect SynEval functionality.\n",
            "   If you want to avoid conflicts completely, consider using a fresh virtual environment.\n",
            "🔧 Setting up NLTK data...\n",
            "📦 Downloading NLTK data packages...\n",
            "  Downloading punkt...\n",
            "  ✅ punkt downloaded successfully\n",
            "  Downloading punkt_tab...\n",
            "  ✅ punkt_tab downloaded successfully\n",
            "  Downloading averaged_perceptron_tagger...\n",
            "  ✅ averaged_perceptron_tagger downloaded successfully\n",
            "  Downloading maxent_ne_chunker...\n",
            "  ✅ maxent_ne_chunker downloaded successfully\n",
            "  Downloading words...\n",
            "  ✅ words downloaded successfully\n",
            "  Downloading stopwords...\n",
            "  ✅ stopwords downloaded successfully\n",
            "\n",
            "🎉 NLTK data setup completed!\n",
            "📁 Data location: /root/nltk_data\n",
            "📁 Created plots directory: ./plots\n",
            "\n",
            "🧪 Testing installation...\n",
            "✅ Sentence tokenization: ['Hello world!', 'This is a test sentence.', 'How are you?']\n",
            "✅ Word tokenization: ['Hello', 'world', '!', 'This', 'is']...\n",
            "✅ Stopwords loaded: 198 words\n",
            "✅ Core dependencies (pandas, numpy, matplotlib, seaborn) working\n",
            "🎉 Installation test passed!\n",
            "\n",
            "✅ SynEval environment preparation completed successfully!\n",
            "You can now run SynEval without any issues.\n",
            "\n",
            "📝 Next steps:\n",
            "  1. Run: python run.py --help\n",
            "  2. Check the README.md for usage examples\n",
            "  3. Example command:\n",
            "     python run.py --synthetic data.csv --original data.csv --metadata metadata.json --dimension fidelity --plot\n"
          ]
        }
      ],
      "source": [
        "!python prepare_environment.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZlY0SD316qt"
      },
      "source": [
        "To test fidelity evaluation, default synthetic data, original data, and metadata files are provided. The results are generated in the file named fidelity_results.json. Plots are generated inside ./plots directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVu0EDQcfOS5",
        "outputId": "e6c2ad90-2849-482a-af90-8114949df414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-10 01:24:59.960648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752110700.180106    4279 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752110700.242745    4279 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO:__main__:Loading synthetic data from claude.csv\n",
            "INFO:__main__:Loading original data from real_10k.csv\n",
            "INFO:__main__:Loading metadata from metadata.json\n",
            "INFO:__main__:Running fidelity evaluation...\n",
            "INFO:fidelity:GPU acceleration available - using CUDA\n",
            "INFO:fidelity:Running SDV diagnostic evaluation...\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: 100% 9/9 [00:00<00:00, 487.51it/s]\n",
            "Data Validity Score: 75.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: 100% 1/1 [00:00<00:00, 438.09it/s]\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 87.5%\n",
            "\n",
            "INFO:fidelity:Diagnostic evaluation completed. Overall score: 0.875\n",
            "INFO:fidelity:Running SDV quality evaluation...\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: 100% 9/9 [00:00<00:00, 255.96it/s]\n",
            "Column Shapes Score: 57.1%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: 100% 36/36 [00:00<00:00, 1471.79it/s]\n",
            "Column Pair Trends Score: 67.14%\n",
            "\n",
            "Overall Score (Average): 62.12%\n",
            "\n",
            "INFO:fidelity:Quality evaluation completed. Overall score: 0.6212\n",
            "INFO:__main__:Saving results to fidelity_results.json\n",
            "INFO:__main__:Results successfully saved to fidelity_results.json\n",
            "\n",
            "📈 Evaluation Results Summary\n",
            "==================================================\n",
            "\n",
            "🔍 FIDELITY EVALUATION\n",
            "------------------------------\n",
            "Data Validity: 0.75\n",
            "Data Structure: 1.0\n",
            "Overall Score: 0.875\n",
            "Average Numerical Fidelity: 0.448\n",
            "INFO:__main__:Generating plots for evaluation results...\n",
            "INFO:plotting:Generating fidelity plots...\n",
            "INFO:plotting:Generating utility plots...\n",
            "INFO:plotting:Generating diversity plots...\n",
            "INFO:plotting:Generating privacy plots...\n",
            "INFO:__main__:Plots saved to ./plots directory.\n",
            "INFO:__main__:Evaluation complete!\n"
          ]
        }
      ],
      "source": [
        "!python run.py \\\n",
        "    --synthetic claude.csv \\\n",
        "    --original real_10k.csv \\\n",
        "    --metadata metadata.json \\\n",
        "    --dimensions fidelity \\\n",
        "    --utility-input text \\\n",
        "    --utility-output rating \\\n",
        "    --output fidelity_results.json \\\n",
        "    --plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXl-6BFi1_5d"
      },
      "source": [
        "To test utility evaluation, default synthetic data, original data, and metadata files are provided. The default downstreaming task is to train a classifier to predict rating values based on review text. The results are generated in the file named utility_results.json. Plots are generated inside ./plots directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IiqocmtijJ1",
        "outputId": "ae8a9844-180d-47ce-9f00-57d541d798a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-10 01:26:41.141053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752110801.174889    4743 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752110801.185191    4743 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO:__main__:Loading synthetic data from claude.csv\n",
            "INFO:__main__:Loading original data from real_10k.csv\n",
            "INFO:__main__:Loading metadata from metadata.json\n",
            "INFO:__main__:Running utility evaluation...\n",
            "INFO:utility:GPU acceleration available - using CUDA\n",
            "INFO:utility:Using all synthetic data (300 samples) for training\n",
            "INFO:utility:Training size: 300, Test size: 300\n",
            "INFO:utility:All unique target values: [1.0, 2.0, 3.0, 4.0, 5.0]\n",
            "INFO:utility:Encoded classes: [1. 2. 3. 4. 5.]\n",
            "INFO:utility:Expected class range: 0 to 4\n",
            "INFO:utility:Training model on real data...\n",
            "INFO:utility:Training model on synthetic data...\n",
            "INFO:__main__:Saving results to utility_results.json\n",
            "INFO:__main__:Results successfully saved to utility_results.json\n",
            "\n",
            "📈 Evaluation Results Summary\n",
            "==================================================\n",
            "\n",
            "🔍 UTILITY EVALUATION\n",
            "------------------------------\n",
            "Real Data Model Accuracy: 0.543\n",
            "Synthetic Data Model Accuracy: 0.207\n",
            "Performance Ratio: 0.380\n",
            "INFO:__main__:Generating plots for evaluation results...\n",
            "INFO:plotting:Generating fidelity plots...\n",
            "INFO:plotting:Generating utility plots...\n",
            "INFO:plotting:Generating diversity plots...\n",
            "INFO:plotting:Generating privacy plots...\n",
            "INFO:__main__:Plots saved to ./plots directory.\n",
            "INFO:__main__:Evaluation complete!\n"
          ]
        }
      ],
      "source": [
        "!python run.py \\\n",
        "    --synthetic claude.csv \\\n",
        "    --original real_10k.csv \\\n",
        "    --metadata metadata.json \\\n",
        "    --dimensions utility \\\n",
        "    --utility-input text \\\n",
        "    --utility-output rating \\\n",
        "    --output utility_results.json \\\n",
        "    --plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EsKNfNP2CqI"
      },
      "source": [
        "To test diversity evaluation, default synthetic data, original data, and metadata files are provided. The results are generated in the file named diversity_results.json. Plots are generated inside ./plots directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuajcGzvjrVd",
        "outputId": "3aefa413-0001-4554-f84a-ebe61ce1cdee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-10 01:31:48.534964: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752111108.554732    6081 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752111108.561019    6081 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO:__main__:Loading synthetic data from claude.csv\n",
            "INFO:__main__:Loading original data from real_10k.csv\n",
            "INFO:__main__:Loading metadata from metadata.json\n",
            "INFO:__main__:Running diversity evaluation...\n",
            "INFO:diversity:Using device: cuda\n",
            "INFO:diversity:GPU acceleration enabled\n",
            "INFO:diversity:Evaluating text diversity for columns: ['title', 'text', 'asin', 'parent_asin', 'user_id']\n",
            "Evaluating text columns:   0% 0/5 [00:00<?, ?it/s]INFO:diversity:Evaluating synthetic data for column: title\n",
            "INFO:diversity:Using cached lexical diversity results for title\n",
            "INFO:diversity:Using cached semantic diversity results for title\n",
            "INFO:diversity:Using cached sentiment diversity results for title\n",
            "INFO:diversity:Using cached results for real data column: title\n",
            "Evaluating text columns:  20% 1/5 [00:03<00:12,  3.22s/it]INFO:diversity:Evaluating synthetic data for column: text\n",
            "INFO:diversity:Using cached lexical diversity results for text\n",
            "INFO:diversity:Using cached semantic diversity results for text\n",
            "INFO:diversity:Using cached sentiment diversity results for text\n",
            "INFO:diversity:Using cached results for real data column: text\n",
            "Evaluating text columns:  40% 2/5 [00:06<00:10,  3.45s/it]INFO:diversity:Evaluating synthetic data for column: asin\n",
            "INFO:diversity:Using cached lexical diversity results for asin\n",
            "INFO:diversity:Using cached semantic diversity results for asin\n",
            "INFO:diversity:Using cached sentiment diversity results for asin\n",
            "INFO:diversity:Using cached results for real data column: asin\n",
            "Evaluating text columns:  60% 3/5 [00:10<00:06,  3.42s/it]INFO:diversity:Evaluating synthetic data for column: parent_asin\n",
            "INFO:diversity:Using cached lexical diversity results for parent_asin\n",
            "INFO:diversity:Using cached semantic diversity results for parent_asin\n",
            "INFO:diversity:Using cached sentiment diversity results for parent_asin\n",
            "INFO:diversity:Using cached results for real data column: parent_asin\n",
            "Evaluating text columns:  80% 4/5 [00:13<00:03,  3.23s/it]INFO:diversity:Evaluating synthetic data for column: user_id\n",
            "INFO:diversity:Using cached lexical diversity results for user_id\n",
            "INFO:diversity:Using cached semantic diversity results for user_id\n",
            "INFO:diversity:Using cached sentiment diversity results for user_id\n",
            "INFO:diversity:Using cached results for real data column: user_id\n",
            "Evaluating text columns: 100% 5/5 [00:16<00:00,  3.28s/it]\n",
            "INFO:__main__:Diversity evaluation completed successfully\n",
            "INFO:__main__:Saving results to diversity_results.json\n",
            "INFO:__main__:Results successfully saved to diversity_results.json\n",
            "\n",
            "📈 Evaluation Results Summary\n",
            "==================================================\n",
            "\n",
            "🔍 DIVERSITY EVALUATION\n",
            "------------------------------\n",
            "Average Tabular Coverage: 58.5%\n",
            "INFO:__main__:Generating plots for evaluation results...\n",
            "INFO:plotting:Generating fidelity plots...\n",
            "INFO:plotting:Generating utility plots...\n",
            "INFO:plotting:Generating diversity plots...\n",
            "INFO:plotting:Generating privacy plots...\n",
            "INFO:__main__:Plots saved to ./plots directory.\n",
            "INFO:__main__:Evaluation complete!\n"
          ]
        }
      ],
      "source": [
        "!python run.py \\\n",
        "    --synthetic claude.csv \\\n",
        "    --original real_10k.csv \\\n",
        "    --metadata metadata.json \\\n",
        "    --dimensions diversity \\\n",
        "    --utility-input text \\\n",
        "    --utility-output rating \\\n",
        "    --output diversity_results.json \\\n",
        "    --plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z52g-hvT2FQu"
      },
      "source": [
        "To test privacy evaluation, default synthetic data, original data, and metadata files are provided. The results are generated in the file named privacy_results.json. Plots are generated inside ./plots directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYjQigbglef5",
        "outputId": "65d3b529-92f3-4398-eed8-13182b199503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-10 01:33:28.247448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752111208.267148    6524 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752111208.273170    6524 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO:__main__:Loading synthetic data from claude.csv\n",
            "INFO:__main__:Loading original data from real_10k.csv\n",
            "INFO:__main__:Loading metadata from metadata.json\n",
            "INFO:__main__:Running privacy evaluation...\n",
            "INFO:privacy:Using CUDA for acceleration\n",
            "INFO:privacy:Loading Flair NER model (this may take a few minutes)...\n",
            "pytorch_model.bin: 100% 2.24G/2.24G [00:15<00:00, 140MB/s]\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 150kB/s]\n",
            "config.json: 100% 616/616 [00:00<00:00, 3.47MB/s]\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:01<00:00, 2.95MB/s]\n",
            "tokenizer.json: 100% 9.10M/9.10M [00:06<00:00, 1.45MB/s]\n",
            "2025-07-10 01:34:15,420 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
            "INFO:privacy:Loaded Flair NER model successfully\n",
            "INFO:privacy:Starting comprehensive privacy evaluation...\n",
            "INFO:privacy:Starting membership inference attack evaluation...\n",
            "INFO:privacy:Processing text columns for membership inference...\n",
            "INFO:privacy:Processing non-text columns for membership inference...\n",
            "INFO:privacy:Feature dimensions - Synthetic: (300, 1004), Original: (10000, 1004)\n",
            "INFO:privacy:Training membership inference classifier...\n",
            "INFO:privacy:Membership inference results - AUC: 1.000, Avg confidence (syn/orig): 0.961/0.002\n",
            "INFO:privacy:Running text-specific privacy evaluations...\n",
            "INFO:privacy:Using cached original data entities...\n",
            "INFO:privacy:Processing synthetic data entities...\n",
            "Processing entities: 100% 300/300 [00:13<00:00, 23.06text/s]\n",
            "INFO:root:Saved cache for named_entities_synthetic\n",
            "INFO:privacy:Using cached original data nominal mentions...\n",
            "INFO:privacy:Processing synthetic data nominal mentions...\n",
            "Processing nominals: 100% 300/300 [00:00<00:00, 1123.10text/s]\n",
            "INFO:root:Saved cache for nominal_mentions_synthetic\n",
            "INFO:privacy:Using cached original data stylistic outliers...\n",
            "INFO:privacy:Processing synthetic data stylistic outliers...\n",
            "INFO:gensim.models.word2vec:collecting all words and their counts\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO:gensim.models.word2vec:collected 366 word types from a corpus of 674 raw words and 300 sentences\n",
            "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 366 unique words (100.00% of original 366, drops 0)', 'datetime': '2025-07-10T01:34:43.381751', 'gensim': '4.3.3', 'python': '3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]', 'platform': 'Linux-6.1.123+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 674 word corpus (100.00% of original 674, drops 0)', 'datetime': '2025-07-10T01:34:43.381879', 'gensim': '4.3.3', 'python': '3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]', 'platform': 'Linux-6.1.123+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
            "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 366 items\n",
            "INFO:gensim.models.word2vec:sample=0.001 downsamples 144 most-common words\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 522.3707638091098 word corpus (77.5%% of prior 674)', 'datetime': '2025-07-10T01:34:43.383950', 'gensim': '4.3.3', 'python': '3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]', 'platform': 'Linux-6.1.123+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
            "INFO:gensim.models.word2vec:estimated required memory for 366 words and 100 dimensions: 475800 bytes\n",
            "INFO:gensim.models.word2vec:resetting layer weights\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-07-10T01:34:43.389103', 'gensim': '4.3.3', 'python': '3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]', 'platform': 'Linux-6.1.123+-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 4 workers on 366 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-07-10T01:34:43.389213', 'gensim': '4.3.3', 'python': '3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]', 'platform': 'Linux-6.1.123+-x86_64-with-glibc2.35', 'event': 'train'}\n",
            "INFO:gensim.models.word2vec:EPOCH 0: training on 674 raw words (501 effective words) took 0.0s, 548542 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 1: training on 674 raw words (524 effective words) took 0.0s, 551377 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 2: training on 674 raw words (524 effective words) took 0.0s, 588400 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 3: training on 674 raw words (514 effective words) took 0.0s, 553802 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 4: training on 674 raw words (532 effective words) took 0.0s, 460752 effective words/s\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 3370 raw words (2595 effective words) took 0.0s, 228107 effective words/s', 'datetime': '2025-07-10T01:34:43.400649', 'gensim': '4.3.3', 'python': '3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]', 'platform': 'Linux-6.1.123+-x86_64-with-glibc2.35', 'event': 'train'}\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=366, vector_size=100, alpha=0.025>', 'datetime': '2025-07-10T01:34:43.400732', 'gensim': '4.3.3', 'python': '3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]', 'platform': 'Linux-6.1.123+-x86_64-with-glibc2.35', 'event': 'created'}\n",
            "INFO:root:Saved cache for stylistic_outliers_synthetic\n",
            "INFO:privacy:Running Anonymeter privacy evaluations...\n",
            "INFO:privacy:Preparing data for Anonymeter evaluation...\n",
            "INFO:privacy:Original data shape: (10000, 9)\n",
            "INFO:privacy:Synthetic data shape: (300, 9)\n",
            "INFO:privacy:Control data shape: (1000, 9)\n",
            "INFO:privacy:Starting univariate singling out attack...\n",
            "INFO:privacy:Running univariate singling out evaluation...\n",
            "INFO:privacy:Univariate singling out results - Attack rate: SuccessRate(value=0.01619505590002756, error=0.012788437462312275)\n",
            "INFO:privacy:Starting multivariate singling out attack...\n",
            "INFO:privacy:Running multivariate singling out evaluation...\n",
            "INFO:privacy:Multivariate singling out results - Attack rate: SuccessRate(value=0.01849674910349284, error=0.01849674910349284)\n",
            "WARNING:privacy:Multivariate singling out attack is not better than baseline\n",
            "INFO:privacy:Starting linkability attack...\n",
            "INFO:privacy:Running linkability evaluation...\n",
            "INFO:privacy:Linkability results - Attack rate: SuccessRate(value=0.5557191440519985, error=0.13265886383542988)\n",
            "INFO:privacy:Starting inference attack...\n",
            "INFO:privacy:Evaluating inference risk for secret column: rating\n",
            "INFO:privacy:Running inference evaluation for rating...\n",
            "INFO:privacy:Inference results for rating - Attack rate: SuccessRate(value=0.15331765935451483, error=0.06805422275512353)\n",
            "WARNING:privacy:Inference attack for rating is not better than baseline\n",
            "INFO:privacy:Evaluating inference risk for secret column: title\n",
            "INFO:privacy:Running inference evaluation for title...\n",
            "INFO:privacy:Inference results for title - Attack rate: SuccessRate(value=0.01849674910349284, error=0.01849674910349284)\n",
            "WARNING:privacy:Inference attack for title is not better than baseline\n",
            "INFO:privacy:Evaluating inference risk for secret column: text\n",
            "INFO:privacy:Running inference evaluation for text...\n",
            "INFO:privacy:Inference results for text - Attack rate: SuccessRate(value=0.01849674910349284, error=0.01849674910349284)\n",
            "WARNING:privacy:Inference attack for text is not better than baseline\n",
            "INFO:privacy:Evaluating inference risk for secret column: asin\n",
            "INFO:privacy:Running inference evaluation for asin...\n",
            "INFO:privacy:Inference results for asin - Attack rate: SuccessRate(value=0.01849674910349284, error=0.01849674910349284)\n",
            "WARNING:privacy:Inference attack for asin is not better than baseline\n",
            "INFO:privacy:Evaluating inference risk for secret column: parent_asin\n",
            "INFO:privacy:Running inference evaluation for parent_asin...\n",
            "INFO:privacy:Inference results for parent_asin - Attack rate: SuccessRate(value=0.01849674910349284, error=0.01849674910349284)\n",
            "WARNING:privacy:Inference attack for parent_asin is not better than baseline\n",
            "INFO:privacy:Evaluating inference risk for secret column: user_id\n",
            "INFO:privacy:Running inference evaluation for user_id...\n",
            "INFO:privacy:Inference results for user_id - Attack rate: SuccessRate(value=0.01849674910349284, error=0.01849674910349284)\n",
            "WARNING:privacy:Inference attack for user_id is not better than baseline\n",
            "INFO:privacy:Evaluating inference risk for secret column: timestamp\n",
            "INFO:privacy:Running inference evaluation for timestamp...\n",
            "INFO:privacy:Inference results for timestamp - Attack rate: SuccessRate(value=0.01849674910349284, error=0.01849674910349284)\n",
            "WARNING:privacy:Inference attack for timestamp is not better than baseline\n",
            "INFO:privacy:Evaluating inference risk for secret column: helpful_vote\n",
            "INFO:privacy:Running inference evaluation for helpful_vote...\n",
            "INFO:privacy:Inference results for helpful_vote - Attack rate: SuccessRate(value=0.7792718855199742, error=0.07907157386087281)\n",
            "WARNING:privacy:Inference attack for helpful_vote is not better than baseline\n",
            "INFO:privacy:Evaluating inference risk for secret column: verified_purchase\n",
            "INFO:privacy:Running inference evaluation for verified_purchase...\n",
            "INFO:privacy:Inference results for verified_purchase - Attack rate: SuccessRate(value=0.44221960989241915, error=0.09549934359081111)\n",
            "WARNING:privacy:Inference attack for verified_purchase is not better than baseline\n",
            "INFO:privacy:Generating privacy visualizations...\n",
            "INFO:privacy:Anonymeter evaluation completed successfully\n",
            "INFO:privacy:Anonymeter evaluations completed successfully\n",
            "INFO:privacy:Privacy evaluation completed\n",
            "INFO:__main__:Privacy evaluation completed successfully\n",
            "INFO:__main__:Saving results to privacy_results.json\n",
            "INFO:__main__:Results successfully saved to privacy_results.json\n",
            "\n",
            "📈 Evaluation Results Summary\n",
            "==================================================\n",
            "\n",
            "🔍 PRIVACY EVALUATION\n",
            "------------------------------\n",
            "Membership Inference Risk: high\n",
            "MIA AUC Score: 1.000\n",
            "Exact Match Risk: low\n",
            "INFO:__main__:Generating plots for evaluation results...\n",
            "INFO:plotting:Generating fidelity plots...\n",
            "INFO:plotting:Generating utility plots...\n",
            "INFO:plotting:Generating diversity plots...\n",
            "INFO:plotting:Generating privacy plots...\n",
            "INFO:__main__:Plots saved to ./plots directory.\n",
            "INFO:__main__:Evaluation complete!\n"
          ]
        }
      ],
      "source": [
        "!python run.py \\\n",
        "    --synthetic claude.csv \\\n",
        "    --original real_10k.csv \\\n",
        "    --metadata metadata.json \\\n",
        "    --dimensions privacy \\\n",
        "    --utility-input text \\\n",
        "    --utility-output rating \\\n",
        "    --output privacy_results.json \\\n",
        "    --plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BVNEVEi_3-I"
      },
      "source": [
        "## Additional Tools\n",
        "\n",
        "### Amazon Fashion Dataset - Named Entity Recognition Analysis\n",
        "\n",
        "SynEval includes a specialized tool for analyzing large text datasets using Named Entity Recognition (NER). The `amazon_fashion_ner_analysis_fast.py` script performs comprehensive NER analysis on the Amazon Fashion dataset, processing 10k+ records efficiently.\n",
        "\n",
        "#### Features\n",
        "\n",
        "- **Large Dataset Processing**: Efficiently handles 10k+ records with batch processing\n",
        "- **Entity Density Analysis**: Calculates and analyzes entity density for each text\n",
        "- **Comprehensive Reporting**: Generates multiple detailed report files\n",
        "- **Top 200 High Entity Texts**: Identifies and reports texts with the most entities\n",
        "- **Visualizations**: Creates charts and graphs for better understanding\n",
        "- **Caching**: Automatic caching for faster subsequent runs\n",
        "- **Progress Tracking**: Real-time progress bars for long-running operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4_z1P7F_2aY",
        "outputId": "536cf7a1-1f74-45e8-9a91-56fd3ce4f815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-10 02:14:56.087656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752113696.107454   17420 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752113696.113786   17420 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-10 02:14:59,606 - INFO - Initializing Fast Amazon Fashion NER Analyzer...\n",
            "2025-07-10 02:14:59,660 - INFO - Loading Flair NER model (this may take a few minutes)...\n",
            "Loading Flair NER model...\n",
            "Using GPU: Tesla T4\n",
            "Loading model to cuda:0...\n",
            "2025-07-10 02:15:00,969 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
            "Moving model to cuda:0...\n",
            "Model loaded successfully on cuda:0\n",
            "2025-07-10 02:15:01,153 - INFO - Loaded Flair NER model successfully\n",
            "2025-07-10 02:15:01,153 - INFO - Starting analysis...\n",
            "============================================================\n",
            "AMAZON FASHION NER ANALYSIS - FAST VERSION\n",
            "============================================================\n",
            "2025-07-10 02:15:01,153 - INFO - Loading dataset from real_10k.csv...\n",
            "Loading dataset...\n",
            "2025-07-10 02:15:01,201 - INFO - Loaded 10000 samples from dataset\n",
            "Preparing texts...\n",
            "2025-07-10 02:15:01,204 - INFO - Processing 9468 non-empty texts (filtered from 10000)\n",
            "Starting entity processing...\n",
            "2025-07-10 02:15:01,204 - INFO - Processing entities...\n",
            "Using GPU: Tesla T4\n",
            "Using GPU batch size: 128\n",
            "Processing 9468 texts in 74 batches...\n",
            "Processing batch 74/74: 100% 9468/9468 [01:09<00:00, 136.44text/s, batch=74/74, entities=17, avg_entities=0.1]\n",
            "Creating analysis...\n",
            "Saving results to cache...\n",
            "Analysis completed successfully!\n",
            "2025-07-10 02:16:11,443 - INFO - Generating reports...\n",
            "============================================================\n",
            "GENERATING REPORTS\n",
            "============================================================\n",
            "Generating reports...\n",
            "1/4 - Generating main analysis report...\n",
            "2/4 - Generating top 200 high entity texts report...\n",
            "3/4 - Generating entity density analysis report...\n",
            "4/4 - Generating visualizations...\n",
            "All reports generated successfully in ./reports\n",
            "2025-07-10 02:16:13,725 - INFO - Reports generated in ./reports\n",
            "2025-07-10 02:16:13,725 - INFO - Analysis completed successfully!\n"
          ]
        }
      ],
      "source": [
        "!python amazon_fashion_ner_analysis_fast.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
