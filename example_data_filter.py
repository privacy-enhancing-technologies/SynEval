#!/usr/bin/env python3
"""
æ•°æ®ç­›é€‰å·¥å…·ä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ data_filter.py æ¥ç­›é€‰é«˜è´¨é‡æ•°æ®ã€‚
"""

import pandas as pd
import json
import os
from pathlib import Path

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®é›†å’Œå…ƒæ•°æ®"""
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    data = {
        'review': [
            "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨ï¼Œè´¨é‡å¾ˆæ£’ï¼æˆ‘éå¸¸æ»¡æ„è¿™æ¬¡è´­ä¹°ï¼Œå¼ºçƒˆæ¨èç»™å¤§å®¶ã€‚",
            "ä¸å¤ªæ»¡æ„ï¼Œä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜ã€‚",
            "ä¸€èˆ¬èˆ¬ï¼Œè¿˜å¯ä»¥æ¥å—ï¼Œä½†æ˜¯æœ‰æ”¹è¿›ç©ºé—´ã€‚",
            "éå¸¸æ¨èï¼Œæ€§ä»·æ¯”å¾ˆé«˜ï¼Œè´¨é‡ä¹Ÿä¸é”™ï¼Œå€¼å¾—è´­ä¹°ã€‚",
            "è´¨é‡ä¸é”™ï¼Œä½†æ˜¯åŒ…è£…éœ€è¦æ”¹è¿›ï¼Œæ•´ä½“æ¥è¯´è¿˜å¯ä»¥ã€‚",
            "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨ï¼Œè´¨é‡å¾ˆæ£’ï¼",  # çŸ­è¯„è®º
            "ä¸å¤ªæ»¡æ„ï¼Œä»·æ ¼å¤ªè´µäº†",         # çŸ­è¯„è®º
            "ä¸€èˆ¬èˆ¬ï¼Œè¿˜å¯ä»¥æ¥å—",           # çŸ­è¯„è®º
            "éå¸¸æ¨èï¼Œæ€§ä»·æ¯”å¾ˆé«˜",         # çŸ­è¯„è®º
            "è´¨é‡ä¸é”™ï¼Œä½†æ˜¯åŒ…è£…éœ€è¦æ”¹è¿›"    # çŸ­è¯„è®º
        ],
        'rating': [5, 2, 3, 5, 4, 5, 2, 3, 5, 4],
        'category': ['ç”µå­äº§å“', 'æœè£…', 'é£Ÿå“', 'ç”µå­äº§å“', 'å®¶å±…', 
                    'ç”µå­äº§å“', 'æœè£…', 'é£Ÿå“', 'ç”µå­äº§å“', 'å®¶å±…'],
        'user_id': ['user_001', 'user_002', 'user_003', 'user_004', 'user_005',
                   'user_006', 'user_007', 'user_008', 'user_009', 'user_010'],
        'price': [299.99, 89.50, 15.99, 599.99, 45.00,
                 299.99, 89.50, 15.99, 599.99, 45.00]
    }
    
    df = pd.DataFrame(data)
    
    # åˆ›å»ºå…ƒæ•°æ®
    metadata = {
        "columns": {
            "review": {"sdtype": "text"},
            "rating": {"sdtype": "numerical"},
            "category": {"sdtype": "categorical"},
            "user_id": {"sdtype": "pii"},
            "price": {"sdtype": "numerical"}
        }
    }
    
    return df, metadata

def save_sample_files(df, metadata):
    """ä¿å­˜ç¤ºä¾‹æ–‡ä»¶"""
    
    # ä¿å­˜æ•°æ®
    df.to_csv('sample_dataset.csv', index=False)
    print("âœ… ç¤ºä¾‹æ•°æ®é›†å·²ä¿å­˜: sample_dataset.csv")
    
    # ä¿å­˜å…ƒæ•°æ®
    with open('sample_metadata.json', 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    print("âœ… ç¤ºä¾‹å…ƒæ•°æ®å·²ä¿å­˜: sample_metadata.json")

def run_text_length_filter():
    """è¿è¡Œæ–‡æœ¬é•¿åº¦ç­›é€‰"""
    print("\nğŸ” è¿è¡Œæ–‡æœ¬é•¿åº¦ç­›é€‰...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists('sample_dataset.csv') or not os.path.exists('sample_metadata.json'):
        print("âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_sample_files()")
        return
    
    # è¿è¡Œç­›é€‰
    import subprocess
    cmd = [
        'python', 'data_filter.py',
        '--data', 'sample_dataset.csv',
        '--metadata', 'sample_metadata.json',
        '--output', 'filtered_by_length.csv',
        '--scores-output', 'length_scores.csv',
        '--metrics', 'text_length',
        '--text-columns', 'review',
        '--top-n', '5'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… æ–‡æœ¬é•¿åº¦ç­›é€‰å®Œæˆ")
            print("ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: filtered_by_length.csv")
            print("ğŸ“Š å¾—åˆ†å·²ä¿å­˜åˆ°: length_scores.csv")
        else:
            print("âŒ ç­›é€‰å¤±è´¥:")
            print(result.stderr)
    except Exception as e:
        print(f"âŒ è¿è¡Œç­›é€‰æ—¶å‡ºé”™: {e}")

def run_multi_metric_filter():
    """è¿è¡Œå¤šæŒ‡æ ‡ç­›é€‰"""
    print("\nğŸ” è¿è¡Œå¤šæŒ‡æ ‡ç­›é€‰...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists('sample_dataset.csv') or not os.path.exists('sample_metadata.json'):
        print("âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_sample_files()")
        return
    
    # è¿è¡Œç­›é€‰
    import subprocess
    cmd = [
        'python', 'data_filter.py',
        '--data', 'sample_dataset.csv',
        '--metadata', 'sample_metadata.json',
        '--output', 'filtered_multi_metric.csv',
        '--scores-output', 'multi_metric_scores.csv',
        '--metrics', 'text_length', 'text_quality', 'sentiment',
        '--text-columns', 'review',
        '--weights', '0.5', '0.3', '0.2',
        '--top-n', '5'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… å¤šæŒ‡æ ‡ç­›é€‰å®Œæˆ")
            print("ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: filtered_multi_metric.csv")
            print("ğŸ“Š å¾—åˆ†å·²ä¿å­˜åˆ°: multi_metric_scores.csv")
        else:
            print("âŒ ç­›é€‰å¤±è´¥:")
            print(result.stderr)
    except Exception as e:
        print(f"âŒ è¿è¡Œç­›é€‰æ—¶å‡ºé”™: {e}")

def run_numerical_filter():
    """è¿è¡Œæ•°å€¼ç­›é€‰"""
    print("\nğŸ” è¿è¡Œæ•°å€¼ç­›é€‰...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists('sample_dataset.csv') or not os.path.exists('sample_metadata.json'):
        print("âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_sample_files()")
        return
    
    # è¿è¡Œç­›é€‰
    import subprocess
    cmd = [
        'python', 'data_filter.py',
        '--data', 'sample_dataset.csv',
        '--metadata', 'sample_metadata.json',
        '--output', 'filtered_by_numerical.csv',
        '--scores-output', 'numerical_scores.csv',
        '--metrics', 'numerical_value',
        '--numerical-columns', 'rating', 'price',
        '--numerical-metric-type', 'value',
        '--top-n', '5'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… æ•°å€¼ç­›é€‰å®Œæˆ")
            print("ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: filtered_by_numerical.csv")
            print("ğŸ“Š å¾—åˆ†å·²ä¿å­˜åˆ°: numerical_scores.csv")
        else:
            print("âŒ ç­›é€‰å¤±è´¥:")
            print(result.stderr)
    except Exception as e:
        print(f"âŒ è¿è¡Œç­›é€‰æ—¶å‡ºé”™: {e}")

def run_diversity_filter():
    """è¿è¡Œå¤šæ ·æ€§ç­›é€‰"""
    print("\nğŸ” è¿è¡Œå¤šæ ·æ€§ç­›é€‰...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists('sample_dataset.csv') or not os.path.exists('sample_metadata.json'):
        print("âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_sample_files()")
        return
    
    # è¿è¡Œç­›é€‰
    import subprocess
    cmd = [
        'python', 'data_filter.py',
        '--data', 'sample_dataset.csv',
        '--metadata', 'sample_metadata.json',
        '--output', 'filtered_by_diversity.csv',
        '--scores-output', 'diversity_scores.csv',
        '--metrics', 'categorical_diversity',
        '--categorical-columns', 'category',
        '--top-n', '5'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… å¤šæ ·æ€§ç­›é€‰å®Œæˆ")
            print("ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: filtered_by_diversity.csv")
            print("ğŸ“Š å¾—åˆ†å·²ä¿å­˜åˆ°: diversity_scores.csv")
        else:
            print("âŒ ç­›é€‰å¤±è´¥:")
            print(result.stderr)
    except Exception as e:
        print(f"âŒ è¿è¡Œç­›é€‰æ—¶å‡ºé”™: {e}")

def display_results():
    """æ˜¾ç¤ºç­›é€‰ç»“æœ"""
    print("\nğŸ“Š ç­›é€‰ç»“æœæ¦‚è§ˆ:")
    
    result_files = [
        ('filtered_by_length.csv', 'æ–‡æœ¬é•¿åº¦ç­›é€‰'),
        ('filtered_multi_metric.csv', 'å¤šæŒ‡æ ‡ç­›é€‰'),
        ('filtered_by_numerical.csv', 'æ•°å€¼ç­›é€‰'),
        ('filtered_by_diversity.csv', 'å¤šæ ·æ€§ç­›é€‰')
    ]
    
    for file_path, description in result_files:
        if os.path.exists(file_path):
            print(f"\nğŸ“„ {description} ({file_path}):")
            try:
                df = pd.read_csv(file_path)
                print(f"  ç­›é€‰å‡º {len(df)} æ¡æ•°æ®")
                
                # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®çš„å…³é”®ä¿¡æ¯
                if 'review' in df.columns:
                    print("  å‰3æ¡è¯„è®º:")
                    for i, review in enumerate(df['review'].head(3)):
                        print(f"    {i+1}. {review[:50]}...")
                
                if 'rating' in df.columns:
                    avg_rating = df['rating'].mean()
                    print(f"  å¹³å‡è¯„åˆ†: {avg_rating:.2f}")
                
            except Exception as e:
                print(f"  âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        else:
            print(f"\nğŸ“„ {description} ({file_path}): æ–‡ä»¶ä¸å­˜åœ¨")

def display_scores():
    """æ˜¾ç¤ºå¾—åˆ†ä¿¡æ¯"""
    print("\nğŸ“Š å¾—åˆ†ä¿¡æ¯æ¦‚è§ˆ:")
    
    score_files = [
        ('length_scores.csv', 'æ–‡æœ¬é•¿åº¦å¾—åˆ†'),
        ('multi_metric_scores.csv', 'å¤šæŒ‡æ ‡å¾—åˆ†'),
        ('numerical_scores.csv', 'æ•°å€¼å¾—åˆ†'),
        ('diversity_scores.csv', 'å¤šæ ·æ€§å¾—åˆ†')
    ]
    
    for file_path, description in score_files:
        if os.path.exists(file_path):
            print(f"\nğŸ“„ {description} ({file_path}):")
            try:
                df = pd.read_csv(file_path)
                
                # æ˜¾ç¤ºå¾—åˆ†ç»Ÿè®¡
                if 'total_score' in df.columns:
                    print(f"  æ€»åˆ†ç»Ÿè®¡:")
                    print(f"    å¹³å‡åˆ†: {df['total_score'].mean():.3f}")
                    print(f"    æœ€é«˜åˆ†: {df['total_score'].max():.3f}")
                    print(f"    æœ€ä½åˆ†: {df['total_score'].min():.3f}")
                
                # æ˜¾ç¤ºå„æŒ‡æ ‡å¾—åˆ†
                score_columns = [col for col in df.columns if col.startswith('score_')]
                for col in score_columns:
                    metric_name = col.replace('score_', '')
                    mean_score = df[col].mean()
                    print(f"    {metric_name}: {mean_score:.3f}")
                
            except Exception as e:
                print(f"  âŒ è¯»å–å¾—åˆ†æ–‡ä»¶å¤±è´¥: {e}")
        else:
            print(f"\nğŸ“„ {description} ({file_path}): æ–‡ä»¶ä¸å­˜åœ¨")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ•°æ®ç­›é€‰å·¥å…·ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("\n1ï¸âƒ£ åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    df, metadata = create_sample_data()
    save_sample_files(df, metadata)
    
    # 2. è¿è¡Œæ–‡æœ¬é•¿åº¦ç­›é€‰
    print("\n2ï¸âƒ£ è¿è¡Œæ–‡æœ¬é•¿åº¦ç­›é€‰...")
    run_text_length_filter()
    
    # 3. è¿è¡Œå¤šæŒ‡æ ‡ç­›é€‰
    print("\n3ï¸âƒ£ è¿è¡Œå¤šæŒ‡æ ‡ç­›é€‰...")
    run_multi_metric_filter()
    
    # 4. è¿è¡Œæ•°å€¼ç­›é€‰
    print("\n4ï¸âƒ£ è¿è¡Œæ•°å€¼ç­›é€‰...")
    run_numerical_filter()
    
    # 5. è¿è¡Œå¤šæ ·æ€§ç­›é€‰
    print("\n5ï¸âƒ£ è¿è¡Œå¤šæ ·æ€§ç­›é€‰...")
    run_diversity_filter()
    
    # 6. æ˜¾ç¤ºç»“æœ
    print("\n6ï¸âƒ£ æ˜¾ç¤ºç­›é€‰ç»“æœ...")
    display_results()
    
    # 7. æ˜¾ç¤ºå¾—åˆ†ä¿¡æ¯
    print("\n7ï¸âƒ£ æ˜¾ç¤ºå¾—åˆ†ä¿¡æ¯...")
    display_scores()
    
    print("\nâœ… ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
    print("\nğŸ’¡ æç¤º:")
    print("   - æŸ¥çœ‹ç”Ÿæˆçš„ CSV æ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœ")
    print("   - å°è¯•è°ƒæ•´æƒé‡å‚æ•°æ¥ä¼˜åŒ–ç­›é€‰æ•ˆæœ")
    print("   - å‚è€ƒ README_data_filter.md äº†è§£æ›´å¤šç”¨æ³•")
    print("\nğŸ¯ å®é™…åº”ç”¨åœºæ™¯:")
    print("   - ç­›é€‰é«˜è´¨é‡é•¿è¯„è®ºç”¨äºè®­ç»ƒ")
    print("   - é€‰æ‹©é«˜ä»·å€¼äº§å“æ•°æ®")
    print("   - ç­›é€‰å¤šæ ·åŒ–çš„åˆ†ç±»æ•°æ®")
    print("   - é€‰æ‹©å¤æ‚æ–‡æœ¬ç”¨äºç‰¹å®šä»»åŠ¡")

if __name__ == "__main__":
    main() 