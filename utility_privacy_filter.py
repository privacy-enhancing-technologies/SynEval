#!/usr/bin/env python3

import argparse
import pandas as pd
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
from textblob import TextBlob


class UtilityPrivacyFilter:
    def __init__(self, data: pd.DataFrame, metadata: Dict):
        """
        åŸºäºæƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦å’ŒPIIéšç§ä¿æŠ¤çš„æ•°æ®ç­›é€‰å™¨
        
        Args:
            data: è¦ç­›é€‰çš„æ•°æ®é›†
            metadata: æ•°æ®é›†çš„å…ƒæ•°æ®ä¿¡æ¯
        """
        self.data = data.copy()
        self.metadata = metadata
        self.logger = logging.getLogger(__name__)

    def calculate_sentiment_rating_alignment_scores(self, text_columns: List[str], rating_column: str) -> pd.Series:
        """è®¡ç®—æƒ…æ„Ÿä¸è¯„åˆ†çš„åŒ¹é…åº¦å¾—åˆ†ï¼ˆUtilityç»´åº¦ï¼‰"""
        scores = pd.Series(0.0, index=self.data.index)
        
        if rating_column not in self.data.columns:
            self.logger.warning(f"è¯„åˆ†åˆ— {rating_column} ä¸å­˜åœ¨ï¼Œè·³è¿‡æƒ…æ„Ÿè¯„åˆ†åŒ¹é…è®¡ç®—")
            return scores
        
        if not text_columns:
            self.logger.warning("æ²¡æœ‰æŒ‡å®šæ–‡æœ¬åˆ—ï¼Œæƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦å¾—åˆ†å°†ä¸º0")
            return scores
        
        try:
            for col in text_columns:
                if col in self.data.columns:
                    texts = self.data[col].astype(str)
                    ratings = pd.to_numeric(self.data[rating_column], errors='coerce').fillna(3.0)
                    
                    # è®¡ç®—æƒ…æ„Ÿææ€§
                    sentiment_scores = texts.apply(lambda x: TextBlob(x).sentiment.polarity)
                    
                    # å°†æƒ…æ„Ÿææ€§è½¬æ¢ä¸ºæœŸæœ›çš„è¯„åˆ†èŒƒå›´
                    # è´Ÿé¢æƒ…æ„Ÿ(-1åˆ°0) -> æœŸæœ›è¯„åˆ†1-3
                    # ä¸­æ€§æƒ…æ„Ÿ(0) -> æœŸæœ›è¯„åˆ†3
                    # æ­£é¢æƒ…æ„Ÿ(0åˆ°1) -> æœŸæœ›è¯„åˆ†3-5
                    expected_ratings = 3.0 + sentiment_scores * 2.0
                    
                    # è®¡ç®—å®é™…è¯„åˆ†ä¸æœŸæœ›è¯„åˆ†çš„åŒ¹é…åº¦
                    # ä½¿ç”¨è´Ÿçš„ç»å¯¹å·®å€¼ï¼Œå·®å€¼è¶Šå°å¾—åˆ†è¶Šé«˜
                    alignment_scores = 1.0 - abs(ratings - expected_ratings) / 4.0  # 4.0æ˜¯æœ€å¤§å¯èƒ½å·®å€¼
                    alignment_scores = alignment_scores.clip(0.0, 1.0)  # é™åˆ¶åœ¨0-1èŒƒå›´
                    
                    self.logger.debug(f"åˆ— {col} çš„æƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦èŒƒå›´: {alignment_scores.min():.3f} - {alignment_scores.max():.3f}")
                    scores += alignment_scores
                else:
                    self.logger.warning(f"æ–‡æœ¬åˆ— {col} ä¸å­˜åœ¨äºæ•°æ®ä¸­")
            
            return scores / len(text_columns) if text_columns else scores
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—æƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦æ—¶å‡ºé”™: {e}")
            return pd.Series(0.5, index=self.data.index)

    def calculate_named_entities_scores(self, text_columns: List[str]) -> pd.Series:
        """è®¡ç®—å‘½åå®ä½“å¾—åˆ†ï¼ˆPrivacyç»´åº¦ï¼Œå®ä½“è¶Šå°‘å¾—åˆ†è¶Šé«˜ï¼‰"""
        scores = pd.Series(0.0, index=self.data.index)
        
        if not text_columns:
            self.logger.warning("æ²¡æœ‰æŒ‡å®šæ–‡æœ¬åˆ—ï¼Œå‘½åå®ä½“å¾—åˆ†å°†ä¸º0")
            return scores
        
        try:
            from flair.models import SequenceTagger
            from flair.data import Sentence
            
            # åˆå§‹åŒ–NERæ¨¡å‹
            tagger = SequenceTagger.load('ner')
            
            for col in text_columns:
                if col in self.data.columns:
                    texts = self.data[col].astype(str)
                    
                    # è®¡ç®—æ¯ä¸ªæ–‡æœ¬çš„å®ä½“æ•°é‡
                    entity_counts = []
                    for text in texts:
                        if pd.isna(text) or text.strip() == '':
                            entity_counts.append(0)
                        else:
                            sentence = Sentence(text)
                            tagger.predict(sentence)
                            entity_count = len(sentence.get_spans('ner'))
                            entity_counts.append(entity_count)
                    
                    # è½¬æ¢ä¸ºå¾—åˆ†ï¼ˆå®ä½“è¶Šå°‘å¾—åˆ†è¶Šé«˜ï¼‰
                    entity_counts = pd.Series(entity_counts)
                    if entity_counts.max() > 0:
                        # æ ‡å‡†åŒ–ï¼šå®ä½“æ•°é‡è¶Šå°‘ï¼Œå¾—åˆ†è¶Šé«˜
                        entity_scores = 1.0 - (entity_counts / entity_counts.max())
                    else:
                        entity_scores = pd.Series(1.0, index=entity_counts.index)
                    
                    scores += entity_scores
                    self.logger.debug(f"åˆ— {col} çš„å‘½åå®ä½“å¾—åˆ†èŒƒå›´: {entity_scores.min():.3f} - {entity_scores.max():.3f}")
                else:
                    self.logger.warning(f"æ–‡æœ¬åˆ— {col} ä¸å­˜åœ¨äºæ•°æ®ä¸­")
            
            return scores / len(text_columns) if text_columns else scores
            
        except Exception as e:
            self.logger.warning(f"NERæ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–è®¡ç®—: {e}")
            # ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºæ–‡æœ¬ç‰¹å¾ä¼°ç®—å®ä½“æ•°é‡
            for col in text_columns:
                if col in self.data.columns:
                    texts = self.data[col].astype(str)
                    
                    # åŸºäºæ–‡æœ¬ç‰¹å¾ä¼°ç®—å®ä½“æ•°é‡
                    # åŒ…å«æ•°å­—ã€å¤§å†™å­—æ¯ã€ç‰¹æ®Šç¬¦å·çš„æ–‡æœ¬å¯èƒ½åŒ…å«æ›´å¤šå®ä½“
                    has_numbers = texts.str.contains(r'\d')
                    has_uppercase = texts.str.contains(r'[A-Z]')
                    has_special_chars = texts.str.contains(r'[^\w\s]')
                    
                    # ç»¼åˆç‰¹å¾å¾—åˆ†ï¼ˆç‰¹å¾è¶Šå°‘ï¼Œå®ä½“å¯èƒ½è¶Šå°‘ï¼‰
                    feature_scores = 1.0 - (has_numbers.astype(int) + has_uppercase.astype(int) + has_special_chars.astype(int)) / 3.0
                    scores += feature_scores
                    
                    self.logger.debug(f"åˆ— {col} çš„ç®€åŒ–å‘½åå®ä½“å¾—åˆ†èŒƒå›´: {feature_scores.min():.3f} - {feature_scores.max():.3f}")
                else:
                    self.logger.warning(f"æ–‡æœ¬åˆ— {col} ä¸å­˜åœ¨äºæ•°æ®ä¸­")
            
            return scores / len(text_columns) if text_columns else scores

    def get_column_types(self) -> Dict[str, List[str]]:
        """è·å–æŒ‰ç±»å‹åˆ†ç»„çš„åˆ—å"""
        column_types = {
            'text': [],
            'numerical': [],
            'categorical': [],
            'pii': []
        }
        
        for col, info in self.metadata.get('columns', {}).items():
            if col in self.data.columns:
                col_type = info.get('sdtype', 'unknown')
                if col_type in column_types:
                    column_types[col_type].append(col)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºPII
                if info.get('pii', False):
                    column_types['pii'].append(col)
        
        self.logger.info(f"æ£€æµ‹åˆ°çš„åˆ—ç±»å‹: {column_types}")
        return column_types

    def get_metadata_config(self) -> Dict:
        """ä»metadataä¸­è·å–é…ç½®ä¿¡æ¯"""
        config = {}
        
        # è·å–æ–‡æœ¬åˆ—é…ç½®
        if 'text_columns' in self.metadata:
            config['text_columns'] = self.metadata['text_columns']
            self.logger.info(f"ä»metadataè·å–æ–‡æœ¬åˆ—: {config['text_columns']}")
        
        # è·å–utilityé…ç½®
        if 'utility' in self.metadata:
            utility_config = self.metadata['utility']
            if 'input_columns' in utility_config and 'output_columns' in utility_config:
                config['utility_input'] = utility_config['input_columns']
                config['utility_output'] = utility_config['output_columns']
                self.logger.info(f"ä»metadataè·å–utilityé…ç½®: è¾“å…¥={config['utility_input']}, è¾“å‡º={config['utility_output']}")
        
        return config

    def calculate_scores(self, config: Dict) -> pd.DataFrame:
        """
        è®¡ç®—åŸºäºæƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦å’ŒPIIéšç§ä¿æŠ¤çš„å¾—åˆ†
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«å„ç»´åº¦çš„å‚æ•°
        
        Returns:
            åŒ…å«æ‰€æœ‰å¾—åˆ†çš„DataFrame
        """
        scores_df = pd.DataFrame(index=self.data.index)
        column_types = self.get_column_types()
        metadata_config = self.get_metadata_config()
        
        # è·å–åˆ—é…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨metadataä¸­çš„é…ç½®ï¼Œç„¶åæ˜¯æŒ‡å®šçš„é…ç½®ï¼Œæœ€åæ˜¯è‡ªåŠ¨æ£€æµ‹
        text_cols = config.get('text_columns') or metadata_config.get('text_columns') or column_types['text']
        rating_col = config.get('rating_column', 'rating')
        
        # å¯¹äºutilityï¼Œä½¿ç”¨metadataä¸­çš„é…ç½®
        utility_input_cols = metadata_config.get('utility_input', text_cols)
        utility_output_cols = metadata_config.get('utility_output', [rating_col])
        
        self.logger.info(f"ä½¿ç”¨çš„æ–‡æœ¬åˆ—: {text_cols}")
        self.logger.info(f"ä½¿ç”¨çš„è¯„åˆ†åˆ—: {rating_col}")
        self.logger.info(f"Utilityè¾“å…¥åˆ—: {utility_input_cols}")
        self.logger.info(f"Utilityè¾“å‡ºåˆ—: {utility_output_cols}")
        
        # 1. Utilityç»´åº¦ (50%æƒé‡) - æƒ…æ„Ÿä¸è¯„åˆ†åŒ¹é…åº¦
        if utility_input_cols and utility_output_cols:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å…¥åˆ—å’Œç¬¬ä¸€ä¸ªè¾“å‡ºåˆ—
            input_col = utility_input_cols[0] if utility_input_cols else text_cols[0]
            output_col = utility_output_cols[0] if utility_output_cols else rating_col
            sentiment_alignment_scores = self.calculate_sentiment_rating_alignment_scores([input_col], output_col)
        else:
            sentiment_alignment_scores = self.calculate_sentiment_rating_alignment_scores(text_cols, rating_col)
        
        self.logger.info(f"æƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦å¾—åˆ†èŒƒå›´: {sentiment_alignment_scores.min():.3f} - {sentiment_alignment_scores.max():.3f}")
        scores_df['utility_score'] = sentiment_alignment_scores
        
        # 2. Privacyç»´åº¦ (50%æƒé‡) - å‘½åå®ä½“æ•°é‡ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰
        named_entities_scores = self.calculate_named_entities_scores(text_cols)
        self.logger.info(f"å‘½åå®ä½“å¾—åˆ†èŒƒå›´: {named_entities_scores.min():.3f} - {named_entities_scores.max():.3f}")
        scores_df['privacy_score'] = named_entities_scores
        
        return scores_df

    def filter_top_data(self, config: Dict, top_n: int = 50) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        ç­›é€‰å‡ºå¾—åˆ†æœ€é«˜çš„å‰Næ¡æ•°æ®
        
        Args:
            config: é…ç½®å­—å…¸
            top_n: è¦ç­›é€‰çš„æ•°æ®æ¡æ•°
        
        Returns:
            (ç­›é€‰åçš„æ•°æ®, å¾—åˆ†DataFrame)
        """
        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡å¾—åˆ†
        scores_df = self.calculate_scores(config)
        
        # è®¡ç®—åŠ æƒæ€»åˆ† (Utility 50%, Privacy 50%)
        total_score = (
            0.50 * scores_df['utility_score'] +
            0.50 * scores_df['privacy_score']
        )
        
        self.logger.info(f"åŠ æƒæ€»åˆ†èŒƒå›´: {total_score.min():.3f} - {total_score.max():.3f}")
        
        scores_df['total_score'] = total_score
        
        # æŒ‰æ€»åˆ†æ’åºå¹¶é€‰æ‹©å‰Næ¡
        top_indices = total_score.nlargest(top_n).index
        filtered_data = self.data.loc[top_indices].copy()
        filtered_scores = scores_df.loc[top_indices].copy()
        
        return filtered_data, filtered_scores


def parse_args():
    parser = argparse.ArgumentParser(description='åŸºäºæƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦å’ŒPIIéšç§ä¿æŠ¤çš„æ•°æ®ç­›é€‰å·¥å…·')

    parser.add_argument('--data', required=True, help='è¦ç­›é€‰çš„æ•°æ®é›†CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--metadata', required=True, help='å…ƒæ•°æ®JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', required=True, help='ç­›é€‰åæ•°æ®çš„è¾“å‡ºè·¯å¾„')
    parser.add_argument('--scores-output', help='å¾—åˆ†æ•°æ®çš„è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--top-n', type=int, default=50, help='è¦ç­›é€‰çš„æ•°æ®æ¡æ•°ï¼ˆé»˜è®¤: 50ï¼‰')

    # åˆ—é…ç½®
    parser.add_argument('--text-columns', nargs='+', help='æ–‡æœ¬åˆ—åï¼ˆå¦‚title, textï¼‰')
    parser.add_argument('--rating-column', default='rating', help='è¯„åˆ†åˆ—åï¼ˆé»˜è®¤: ratingï¼‰')

    parser.add_argument('--log-level', default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], help='è®¾ç½®æ—¥å¿—çº§åˆ«')
    
    return parser

def main():
    parser = parse_args()
    args = parser.parse_args()

    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)

    # åŠ è½½æ•°æ®
    logger.info(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {args.data}")
    data = pd.read_csv(args.data)

    logger.info(f"æ­£åœ¨åŠ è½½å…ƒæ•°æ®: {args.metadata}")
    with open(args.metadata, 'r') as f:
        metadata = json.load(f)

    # åˆ é™¤æœªåœ¨å…ƒæ•°æ®ä¸­å®šä¹‰çš„ _id
    metadata_columns = metadata.get("columns", {})
    if '_id' in data.columns and '_id' not in metadata_columns:
        logger.warning("åœ¨æ•°æ®ä¸­å‘ç° '_id' åˆ—ä½†å…ƒæ•°æ®ä¸­æœªå®šä¹‰ â€” æ­£åœ¨åˆ é™¤")
        data.drop(columns=['_id'], inplace=True)

    # æ„å»ºé…ç½®
    config = {
        'text_columns': args.text_columns,
        'rating_column': args.rating_column,
    }

    # åˆ›å»ºæ•°æ®ç­›é€‰å™¨
    logger.info("æ­£åœ¨åˆ›å»ºUtility-Privacyæ•°æ®ç­›é€‰å™¨...")
    data_filter = UtilityPrivacyFilter(data, metadata)

    # ç­›é€‰æ•°æ®
    logger.info(f"æ­£åœ¨ç­›é€‰å‰{args.top_n}æ¡æ•°æ®...")
    filtered_data, filtered_scores = data_filter.filter_top_data(config, top_n=args.top_n)

    # ä¿å­˜ç»“æœ
    logger.info(f"æ­£åœ¨ä¿å­˜ç­›é€‰åçš„æ•°æ®åˆ°: {args.output}")
    filtered_data.to_csv(args.output, index=False)
    
    if args.scores_output:
        logger.info(f"æ­£åœ¨ä¿å­˜å¾—åˆ†æ•°æ®åˆ°: {args.scores_output}")
        filtered_scores.to_csv(args.scores_output, index=False)

    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print(f"\nğŸ“Š Utility-Privacyæ•°æ®ç­›é€‰ç»“æœæ‘˜è¦")
    print("=" * 50)
    print(f"åŸå§‹æ•°æ®æ¡æ•°: {len(data)}")
    print(f"ç­›é€‰åæ•°æ®æ¡æ•°: {len(filtered_data)}")
    
    print(f"\næƒé‡é…ç½®:")
    print(f"  Utilityç»´åº¦: 50% (æƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦)")
    print(f"  Privacyç»´åº¦: 50% (PII/å®ä½“æ•°é‡)")
    print(f"  Fidelityç»´åº¦: 0% (ä¸å‚ä¸è¯„åˆ†)")
    print(f"  Diversityç»´åº¦: 0% (ä¸å‚ä¸è¯„åˆ†)")
    
    print(f"\nç­›é€‰åæ•°æ®çš„åŸºæœ¬ç»Ÿè®¡:")
    print(f"å¹³å‡æ€»åˆ†: {filtered_scores['total_score'].mean():.3f}")
    print(f"æœ€é«˜æ€»åˆ†: {filtered_scores['total_score'].max():.3f}")
    print(f"æœ€ä½æ€»åˆ†: {filtered_scores['total_score'].min():.3f}")
    
    print(f"Utility (æƒ…æ„Ÿè¯„åˆ†åŒ¹é…åº¦) å¹³å‡å¾—åˆ†: {filtered_scores['utility_score'].mean():.3f}")
    print(f"Privacy (PII/å®ä½“æ•°é‡) å¹³å‡å¾—åˆ†: {filtered_scores['privacy_score'].mean():.3f}")

    logger.info("æ•°æ®ç­›é€‰å®Œæˆ!")

if __name__ == "__main__":
    main() 