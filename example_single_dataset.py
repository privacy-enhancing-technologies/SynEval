#!/usr/bin/env python3
"""
å•æ•°æ®é›†è¯„ä¼°æ¡†æ¶ä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ run_single_dataset.py æ¥è¯„ä¼°å•ä¸ªæ•°æ®é›†çš„è´¨é‡ã€‚
"""

import pandas as pd
import json
import os
from pathlib import Path

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®é›†å’Œå…ƒæ•°æ®"""
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    data = {
        'review': [
            "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨ï¼Œè´¨é‡å¾ˆæ£’ï¼",
            "ä¸å¤ªæ»¡æ„ï¼Œä»·æ ¼å¤ªè´µäº†",
            "ä¸€èˆ¬èˆ¬ï¼Œè¿˜å¯ä»¥æ¥å—",
            "éå¸¸æ¨èï¼Œæ€§ä»·æ¯”å¾ˆé«˜",
            "è´¨é‡ä¸é”™ï¼Œä½†æ˜¯åŒ…è£…éœ€è¦æ”¹è¿›",
            "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨ï¼Œè´¨é‡å¾ˆæ£’ï¼",  # é‡å¤
            "ä¸å¤ªæ»¡æ„ï¼Œä»·æ ¼å¤ªè´µäº†",         # é‡å¤
            "ä¸€èˆ¬èˆ¬ï¼Œè¿˜å¯ä»¥æ¥å—",           # é‡å¤
            "éå¸¸æ¨èï¼Œæ€§ä»·æ¯”å¾ˆé«˜",         # é‡å¤
            "è´¨é‡ä¸é”™ï¼Œä½†æ˜¯åŒ…è£…éœ€è¦æ”¹è¿›"    # é‡å¤
        ],
        'rating': [5, 2, 3, 5, 4, 5, 2, 3, 5, 4],
        'category': ['ç”µå­äº§å“', 'æœè£…', 'é£Ÿå“', 'ç”µå­äº§å“', 'å®¶å±…', 
                    'ç”µå­äº§å“', 'æœè£…', 'é£Ÿå“', 'ç”µå­äº§å“', 'å®¶å±…'],
        'user_id': ['user_001', 'user_002', 'user_003', 'user_004', 'user_005',
                   'user_006', 'user_007', 'user_008', 'user_009', 'user_010'],
        'price': [299.99, 89.50, 15.99, 599.99, 45.00,
                 299.99, 89.50, 15.99, 599.99, 45.00]
    }
    
    df = pd.DataFrame(data)
    
    # åˆ›å»ºå…ƒæ•°æ®
    metadata = {
        "columns": {
            "review": {"sdtype": "text"},
            "rating": {"sdtype": "numerical"},
            "category": {"sdtype": "categorical"},
            "user_id": {"sdtype": "pii"},
            "price": {"sdtype": "numerical"}
        }
    }
    
    return df, metadata

def save_sample_files(df, metadata):
    """ä¿å­˜ç¤ºä¾‹æ–‡ä»¶"""
    
    # ä¿å­˜æ•°æ®
    df.to_csv('sample_dataset.csv', index=False)
    print("âœ… ç¤ºä¾‹æ•°æ®é›†å·²ä¿å­˜: sample_dataset.csv")
    
    # ä¿å­˜å…ƒæ•°æ®
    with open('sample_metadata.json', 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    print("âœ… ç¤ºä¾‹å…ƒæ•°æ®å·²ä¿å­˜: sample_metadata.json")

def run_basic_evaluation():
    """è¿è¡ŒåŸºæœ¬è¯„ä¼°"""
    print("\nğŸ” è¿è¡ŒåŸºæœ¬è¯„ä¼°...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists('sample_dataset.csv') or not os.path.exists('sample_metadata.json'):
        print("âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_sample_files()")
        return
    
    # è¿è¡Œè¯„ä¼°
    import subprocess
    cmd = [
        'python', 'run_single_dataset.py',
        '--data', 'sample_dataset.csv',
        '--metadata', 'sample_metadata.json',
        '--output', 'basic_evaluation_results.json'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… åŸºæœ¬è¯„ä¼°å®Œæˆ")
            print("ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: basic_evaluation_results.json")
        else:
            print("âŒ è¯„ä¼°å¤±è´¥:")
            print(result.stderr)
    except Exception as e:
        print(f"âŒ è¿è¡Œè¯„ä¼°æ—¶å‡ºé”™: {e}")

def run_custom_evaluation():
    """è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°"""
    print("\nğŸ” è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists('sample_dataset.csv') or not os.path.exists('sample_metadata.json'):
        print("âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_sample_files()")
        return
    
    # è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°
    import subprocess
    cmd = [
        'python', 'run_single_dataset.py',
        '--data', 'sample_dataset.csv',
        '--metadata', 'sample_metadata.json',
        '--dimensions', 'summary', 'fidelity', 'diversity',
        '--fidelity-metrics', 'diagnostic', 'quality',
        '--diversity-metrics', 'tabular_diversity',
        '--output', 'custom_evaluation_results.json'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… è‡ªå®šä¹‰è¯„ä¼°å®Œæˆ")
            print("ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: custom_evaluation_results.json")
        else:
            print("âŒ è¯„ä¼°å¤±è´¥:")
            print(result.stderr)
    except Exception as e:
        print(f"âŒ è¿è¡Œè¯„ä¼°æ—¶å‡ºé”™: {e}")

def run_utility_evaluation():
    """è¿è¡Œå®ç”¨æ€§è¯„ä¼°"""
    print("\nğŸ” è¿è¡Œå®ç”¨æ€§è¯„ä¼°...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists('sample_dataset.csv') or not os.path.exists('sample_metadata.json'):
        print("âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_sample_files()")
        return
    
    # è¿è¡Œå®ç”¨æ€§è¯„ä¼°
    import subprocess
    cmd = [
        'python', 'run_single_dataset.py',
        '--data', 'sample_dataset.csv',
        '--metadata', 'sample_metadata.json',
        '--dimensions', 'utility',
        '--utility-input', 'review', 'category', 'price',
        '--utility-output', 'rating',
        '--output', 'utility_evaluation_results.json'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… å®ç”¨æ€§è¯„ä¼°å®Œæˆ")
            print("ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: utility_evaluation_results.json")
        else:
            print("âŒ è¯„ä¼°å¤±è´¥:")
            print(result.stderr)
    except Exception as e:
        print(f"âŒ è¿è¡Œè¯„ä¼°æ—¶å‡ºé”™: {e}")

def display_results():
    """æ˜¾ç¤ºè¯„ä¼°ç»“æœ"""
    print("\nğŸ“Š è¯„ä¼°ç»“æœæ¦‚è§ˆ:")
    
    result_files = [
        'basic_evaluation_results.json',
        'custom_evaluation_results.json', 
        'utility_evaluation_results.json'
    ]
    
    for file_path in result_files:
        if os.path.exists(file_path):
            print(f"\nğŸ“„ {file_path}:")
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    results = json.load(f)
                
                # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                if 'summary' in results:
                    info = results['summary'].get('dataset_info', {})
                    print(f"  æ•°æ®é›†å½¢çŠ¶: {info.get('shape', 'N/A')}")
                    print(f"  å†…å­˜ä½¿ç”¨: {info.get('memory_usage_mb', 'N/A'):.2f} MB")
                    print(f"  é‡å¤è¡Œæ•°: {info.get('duplicate_rows', 'N/A')}")
                
                # æ˜¾ç¤ºè¯„ä¼°ç»´åº¦
                dimensions = [k for k in results.keys() if k != 'summary']
                print(f"  è¯„ä¼°ç»´åº¦: {', '.join(dimensions)}")
                
            except Exception as e:
                print(f"  âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        else:
            print(f"\nğŸ“„ {file_path}: æ–‡ä»¶ä¸å­˜åœ¨")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å•æ•°æ®é›†è¯„ä¼°æ¡†æ¶ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("\n1ï¸âƒ£ åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    df, metadata = create_sample_data()
    save_sample_files(df, metadata)
    
    # 2. è¿è¡ŒåŸºæœ¬è¯„ä¼°
    print("\n2ï¸âƒ£ è¿è¡ŒåŸºæœ¬è¯„ä¼°...")
    run_basic_evaluation()
    
    # 3. è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°
    print("\n3ï¸âƒ£ è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°...")
    run_custom_evaluation()
    
    # 4. è¿è¡Œå®ç”¨æ€§è¯„ä¼°
    print("\n4ï¸âƒ£ è¿è¡Œå®ç”¨æ€§è¯„ä¼°...")
    run_utility_evaluation()
    
    # 5. æ˜¾ç¤ºç»“æœ
    print("\n5ï¸âƒ£ æ˜¾ç¤ºè¯„ä¼°ç»“æœ...")
    display_results()
    
    print("\nâœ… ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
    print("\nğŸ’¡ æç¤º:")
    print("   - æŸ¥çœ‹ç”Ÿæˆçš„ JSON æ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœ")
    print("   - ä½¿ç”¨ --plot å‚æ•°ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    print("   - å‚è€ƒ README_single_dataset.md äº†è§£æ›´å¤šç”¨æ³•")

if __name__ == "__main__":
    main() 